{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from preprocess import Parser\n",
    "from classifier import DiscriminativeClassifier, BinaryGenerativeClassifier\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "# from nltk.collocations import BigramCollocationFinder, TrigramCollocationFinder\n",
    "# from nltk import word_tokenize\n",
    "# import nltk\n",
    "# import re\n",
    "# import operator\n",
    "from topicmodel import LDA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# from wordcloud import WordCloud, STOPWORDS\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meeting</th>\n",
       "      <th>text</th>\n",
       "      <th>seq</th>\n",
       "      <th>D_NBER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>197601</td>\n",
       "      <td>By unanimous vote, the Federal Reserve Bank o...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>197601</td>\n",
       "      <td>Committee, to execute transactions in the Sys...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>197601</td>\n",
       "      <td>The information reviewed at this meeting sugg...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>197601</td>\n",
       "      <td>sales rose sharply, but the increase in the f...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>197601</td>\n",
       "      <td>The exchange value of the dollar against lead...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  meeting                                               text  seq  D_NBER\n",
       "0  197601   By unanimous vote, the Federal Reserve Bank o...    0       0\n",
       "1  197601   Committee, to execute transactions in the Sys...    1       0\n",
       "2  197601   The information reviewed at this meeting sugg...    2       0\n",
       "3  197601   sales rose sharply, but the increase in the f...    3       0\n",
       "4  197601   The exchange value of the dollar against lead...    4       0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_table(StringIO(''.join(l.replace('\\u2028', ' ') for l in open('minutes_data.txt'))),\n",
    "                    parse_dates=['meeting'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped_data = data.groupby('meeting', as_index=False)\n",
    "full_minutes = pd.concat([grouped_data['text'].apply(' '.join), grouped_data.first()], axis=1)\n",
    "full_minutes.drop(['text', 'seq'], axis=1, inplace=True)\n",
    "full_minutes.rename(columns={0: 'text'}, inplace=True)\n",
    "# full_minutes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nber = pd.read_csv('nber.csv', parse_dates=['date'])\n",
    "nber['meeting'] = nber['meeting'].astype(str)\n",
    "\n",
    "nber_lags = pd.concat([nber['meeting'], nber['D_NBER'].shift(-1), \n",
    "                       nber['D_NBER'].shift(-3), nber['D_NBER'].shift(-6), \n",
    "                       nber['D_NBER'].shift(-12),\n",
    "                       nber['date']], \n",
    "                      axis=1)\n",
    "nber_lags.columns = ['meeting', 'D_NBER_1', 'D_NBER_3', 'D_NBER_6', \n",
    "                     'D_NBER_12',\n",
    "                     'meeting_date']\n",
    "\n",
    "full_mins_lags = pd.merge(full_minutes, nber_lags, how='inner', on='meeting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>meeting</th>\n",
       "      <th>D_NBER</th>\n",
       "      <th>D_NBER_1</th>\n",
       "      <th>D_NBER_3</th>\n",
       "      <th>D_NBER_6</th>\n",
       "      <th>D_NBER_12</th>\n",
       "      <th>meeting_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>By unanimous vote, the Federal Reserve Bank o...</td>\n",
       "      <td>197601</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1976-01-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>By unanimous vote, the Federal Reserve Bank o...</td>\n",
       "      <td>197602</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1976-02-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>By unanimous vote, the Federal Reserve Bank o...</td>\n",
       "      <td>197603</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1976-03-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>By unanimous vote, the Federal Reserve Bank o...</td>\n",
       "      <td>197604</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1976-04-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>With Mr. Coldwell, dissenting, the Federal Re...</td>\n",
       "      <td>197605</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1976-05-18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text meeting  D_NBER  \\\n",
       "0   By unanimous vote, the Federal Reserve Bank o...  197601       0   \n",
       "1   By unanimous vote, the Federal Reserve Bank o...  197602       0   \n",
       "2   By unanimous vote, the Federal Reserve Bank o...  197603       0   \n",
       "3   By unanimous vote, the Federal Reserve Bank o...  197604       0   \n",
       "4   With Mr. Coldwell, dissenting, the Federal Re...  197605       0   \n",
       "\n",
       "   D_NBER_1  D_NBER_3  D_NBER_6  D_NBER_12 meeting_date  \n",
       "0       0.0       0.0       0.0        0.0   1976-01-20  \n",
       "1       0.0       0.0       0.0        0.0   1976-02-18  \n",
       "2       0.0       0.0       0.0        0.0   1976-03-16  \n",
       "3       0.0       0.0       0.0        0.0   1976-04-20  \n",
       "4       0.0       0.0       0.0        0.0   1976-05-18  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_mins_lags.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminative classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = full_mins_lags[:200]\n",
    "test = full_mins_lags[200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parser = Parser(lemmatise=False, stem=True, replace_ngrams=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully parsed the corpus. # docs:  322\n",
      "Vocabulary size, # tokens:  4240\n"
     ]
    }
   ],
   "source": [
    "full_docs, full_vocab = parser.parse_vocab(full_mins_lags['text'])\n",
    "full_corpus = parser.parse_corpus(full_docs, full_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully parsed the corpus. # docs:  200\n",
      "Vocabulary size, # tokens:  2680\n",
      "Successfully parsed the corpus. # docs:  122\n",
      "Vocabulary size, # tokens:  2680\n"
     ]
    }
   ],
   "source": [
    "docs, vocab = parser.parse_vocab(train['text'])\n",
    "train_corpus = parser.parse_corpus(docs, vocab)\n",
    "\n",
    "test_docs, _ = parser.parse_vocab(test['text'])\n",
    "test_corpus = parser.parse_corpus(test_docs, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic_model = LDA(K=50, alpha=1, eta=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning completed!\n",
      "Total time taken: 72s\n",
      "ELBO = -980042.328727\n"
     ]
    }
   ],
   "source": [
    "theta_train, beta, elbo = topic_model.fit(train_corpus, full_vocab, max_iter=1000, verbose=False)\n",
    "theta_test, elbo_test = topic_model.infer(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.55116177,  0.30859537,  0.89393774,  0.37074126,  0.41378881,\n",
       "        0.24315921,  2.66765519,  0.26799801,  0.54033646,  0.17832162,\n",
       "        1.1371542 ,  0.32263961,  0.87253761,  0.3145196 ,  0.30489355,\n",
       "        0.2203652 ,  0.26936588,  0.72745534,  0.2592859 ,  0.91879424,\n",
       "        0.22224837,  1.29277881,  0.46490849,  0.72415806,  3.64086494,\n",
       "        0.37580007,  0.16948498,  0.1363942 ,  0.57933333,  0.66670881,\n",
       "        7.23723886,  2.18771144,  0.46065209,  0.31567188,  0.69707819,\n",
       "        0.29444979,  0.66495872,  0.29481655,  0.59642182,  0.35016847,\n",
       "        0.53998118,  0.47425719,  0.17569856,  0.27987473,  0.48828804,\n",
       "        0.19205539,  0.25791276,  0.56347428,  1.18211378,  0.39478349])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "predictions_proba = []\n",
    "coefs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theta_train_rolling = theta_train[:]\n",
    "theta_test_rolling = theta_test[:]\n",
    "train_rolling = train['D_NBER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for n in range(theta_test.shape[0]):\n",
    "    classifier = LogisticRegressionCV(n_jobs=-1, cv=5)\n",
    "    classifier.fit(theta_train_rolling, train_rolling)\n",
    "    \n",
    "    new_doc = theta_test[n, :]\n",
    "    new_y = test['D_NBER'][200+n]\n",
    "    \n",
    "    pred = classifier.predict(new_doc.reshape(1,-1))\n",
    "    pred_proba = classifier.predict_proba(new_doc.reshape(1,-1))\n",
    "    \n",
    "    predictions.append(pred)\n",
    "    predictions_proba.append(pred_proba)\n",
    "    coefs.append(classifier.coef_)\n",
    "    \n",
    "    theta_train_rolling = np.append(theta_train_rolling, new_doc.reshape(1, -1), axis=0)\n",
    "    theta_test_rolling = np.delete(theta_test_rolling, 0, 0)\n",
    "    \n",
    "    train_rolling = np.append(train_rolling, new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8717086834733894\n"
     ]
    }
   ],
   "source": [
    "AUC = roc_auc_score(test['D_NBER'], np.array(predictions_proba)[:,0][:,1])\n",
    "accuracy = accuracy_score(test['D_NBER'], predictions)\n",
    "\n",
    "print(AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theta_tr = pd.read_csv('theta_train_good.csv')\n",
    "theta_te = pd.read_csv('theta_test_good.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab = Dictionary(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "vocab = Dictionary(docs)\n",
    "corpus = [vocab.doc2bow(doc) for doc in docs]\n",
    "test_corpus = [vocab.doc2bow(doc) for doc in test_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_rolling = train['D_NBER']\n",
    "predictions = []\n",
    "predictions_proba = []\n",
    "coefs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for n in range(test.shape[0]):\n",
    "    \n",
    "    gamma = lda.inference(corpus)[0]\n",
    "    theta_train_rolling = gamma / gamma.sum(axis=1).reshape(-1,1)\n",
    "    classifier = LogisticRegressionCV(n_jobs=-1, cv=5, random_state=0)\n",
    "    classifier.fit(theta_train_rolling, train_rolling)\n",
    "    \n",
    "    new_d = test_docs[n]\n",
    "    new_doc = vocab.doc2bow(new_d)\n",
    "    \n",
    "    new_y = test['D_NBER'][200+n]\n",
    "    \n",
    "    lda.update([new_doc])\n",
    "    \n",
    "    gamma_test = lda.inference([new_doc])[0]\n",
    "    theta_test_doc = gamma_test / gamma_test.sum()\n",
    "    \n",
    "    pred = classifier.predict(theta_test_doc.reshape(1,-1))\n",
    "    pred_proba = classifier.predict_proba(theta_test_doc.reshape(1,-1))\n",
    "    \n",
    "    predictions.append(pred)\n",
    "    predictions_proba.append(pred_proba)\n",
    "    coefs.append(classifier.coef_)\n",
    "    \n",
    "    corpus.append(new_doc)\n",
    "    test_corpus = test_corpus[1:]\n",
    "    \n",
    "    train_rolling = np.append(train_rolling, new_y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for n in range(test.shape[0]):\n",
    "    \n",
    "    lda = LdaModel(corpus, \n",
    "            num_topics=50,\n",
    "            id2word=vocab, \n",
    "            alpha='auto',\n",
    "            eta=0.01,\n",
    "            iterations=1000,\n",
    "              passes=5)\n",
    "    \n",
    "    gamma = lda.inference(corpus)[0]\n",
    "    theta_train_rolling = gamma / gamma.sum(axis=1).reshape(-1,1)\n",
    "    \n",
    "    classifier = LogisticRegressionCV(n_jobs=-1, cv=5, random_state=0)\n",
    "    classifier.fit(theta_train_rolling, train_rolling)\n",
    "    \n",
    "    new_d = test_docs[n]\n",
    "    new_doc = vocab.doc2bow(new_d, allow_update=False)\n",
    "    \n",
    "    new_y = test['D_NBER'][200+n]\n",
    "    \n",
    "    gamma_test = lda.inference([new_doc])[0]\n",
    "    theta_test_doc = gamma_test / gamma_test.sum()\n",
    "    \n",
    "    pred = classifier.predict(theta_test_doc.reshape(1,-1))\n",
    "    pred_proba = classifier.predict_proba(theta_test_doc.reshape(1,-1))\n",
    "    \n",
    "    predictions.append(pred)\n",
    "    predictions_proba.append(pred_proba)\n",
    "    coefs.append(classifier.coef_)\n",
    "    \n",
    "    new_doc = vocab.doc2bow(new_d, allow_update=True)\n",
    "    \n",
    "    corpus.append(new_doc)\n",
    "    test_corpus = test_corpus[1:]\n",
    "    \n",
    "    train_rolling = np.append(train_rolling, new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78095238095238095"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(test['D_NBER'], list(map(lambda x: x[1], predictions_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87704918032786883"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([x > 0.022 for x in temp.predict_proba(theta_test_rolling)[:,1]] == test['D_NBER']) / test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(theta_train).to_csv('theta_train.csv')\n",
    "pd.DataFrame(theta_test).to_csv('theta_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(beta).to_csv('beta.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06004202,  0.00150824,  0.03139984, ...,  0.00288369,\n",
       "         0.0067228 ,  0.00238308],\n",
       "       [ 0.09128644,  0.00196479,  0.04509662, ...,  0.0028223 ,\n",
       "         0.00570969,  0.00845637],\n",
       "       [ 0.05396986,  0.01103424,  0.02498124, ...,  0.00255555,\n",
       "         0.00561184,  0.00239275],\n",
       "       ..., \n",
       "       [ 0.04430849,  0.00643218,  0.059252  , ...,  0.01256581,\n",
       "         0.00547095,  0.00019677],\n",
       "       [ 0.04016044,  0.01423206,  0.04415131, ...,  0.02127906,\n",
       "         0.00319519,  0.00134138],\n",
       "       [ 0.04520864,  0.00900138,  0.04339314, ...,  0.02201024,\n",
       "         0.00280463,  0.00023979]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: report number effect adjust ahead effort countri advers quit discuss\n",
      "Topic 1: consum produc lower improv price legisl estim econom spend expans\n",
      "Topic 2: price reserv stabil slightli intermeet restraint period economi spend toward\n",
      "Topic 3: eas countri export capit perform sale uncertainti yen express turmoil\n",
      "Topic 4: longterm tax weak littl concern temporari interestr appreci consider comput\n",
      "Topic 5: sever indic demand reduc weather uncertainti effect unusu result associ\n",
      "Topic 6: inflationari import invest earlier avail event export polici provid posit\n",
      "Topic 7: current economi forecast refer support product anticip inflat project stanc\n",
      "Topic 8: rate year quarter growth busi rang debt committe pressur expans\n",
      "Topic 9: price economi condit risk inventori increas financi demand appreci tight\n",
      "Topic 10: polici tighten time increas action point concern potenti broad suppli\n",
      "Topic 11: household twelv increas previou slightli area food larger amount prospect\n",
      "Topic 12: rel growth near inform period somewhat weaken narrow quarter balanc\n",
      "Topic 13: total behavior veloc committe growth develop nonfinanci rang establish debt\n",
      "Topic 14: larg demand profit consum potenti underli issu build accumul better\n",
      "Topic 15: activ factor evid outlook remain surg time offset sector current\n",
      "Topic 16: rel buildup small probabl use polici bound demand along sector\n",
      "Topic 17: recent higher inflat consider expect growth anticip expans respons slower\n",
      "Topic 18: pace labor rise invest worker intermeet countri strong demand robust\n",
      "Topic 19: aggreg committe rang domest growth debt total establish quarter evalu\n",
      "Topic 20: trade slow balanc price develop econom sever prospect incom final\n",
      "Topic 21: econom capit shipment point order earli type action industri connect\n",
      "Topic 22: despit view accommod diminish construct stanc need concentr polici perhap\n",
      "Topic 23: per cent inflow increas commod bank week polici resist averag\n",
      "Topic 24: intermeet outlook seem structur econgrowth increas assess key expect probabl\n",
      "Topic 25: committe financi direct declin reserv condit suggest growth period averag\n",
      "Topic 26: quarter somewhat develop continu advanc averag econom financi index depress\n",
      "Topic 27: ffr econom direct consist foreign rise part product employ condit\n",
      "Topic 28: year price recent committe pressur balanc expans financi chang increas\n",
      "Topic 29: rang within averag object quarter bank deposit rate oper weight\n",
      "Topic 30: recent come consum overal effect avail forecast activ rise sizabl\n",
      "Topic 31: unit spread stockmkt risk vacanc apparel extend equiti percept deal\n",
      "Topic 32: inflat level consum toward busi reflect util rise firm note\n",
      "Topic 33: year growth declin quarter remain chang level earli littl rate\n",
      "Topic 34: expect continu strong increas especi previou sizabl credit consider longerterm\n",
      "Topic 35: vehicl earlier produc sale index point year activ pace post\n",
      "Topic 36: inventori busi higher capac good expect tend ratio season sector\n",
      "Topic 37: rate continu declin growth current reduc earlier period reflect associ\n",
      "Topic 38: price remain pick product sharpli suggest energi level ahead rebound\n",
      "Topic 39: good produc servic believ increas finish smaller consider reason cost\n",
      "Topic 40: dollar direct level rate bank lower indic limit oper unemploy\n",
      "Topic 41: part expect economi possibl fiscal advanc spend favor aircraft sale\n",
      "Topic 42: overal limit purchas construct disrupt expenditur slack downsid issu cpi\n",
      "Topic 43: pace slow growth rel appear substanti remain reflect expans call\n",
      "Topic 44: rang committe growth quarter transact will account aggreg domest seek\n",
      "Topic 45: inflat outlook avail confid regard build includ low propos central\n",
      "Topic 46: inflat pressur increas resourc equip price food labor project cost\n",
      "Topic 47: concern though busi export competit abroad fund expenditur diminish home\n",
      "Topic 48: effect domest persist asia deceler household action low payrol extent\n",
      "Topic 49: nation year though need like sector retail industri ahead line\n"
     ]
    }
   ],
   "source": [
    "n_top_words = 10\n",
    "for i, topic_dist in enumerate(beta):\n",
    "    topic_words = np.argsort(topic_dist)[:-(n_top_words+1):-1]\n",
    "    top_words = []\n",
    "    for j in topic_words:\n",
    "        top_words.append(topic_model._vocab[j])\n",
    "    print('Topic {}: {}'.format(i, ' '.join(top_words)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
